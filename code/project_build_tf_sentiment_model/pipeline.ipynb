{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3fe6f2d",
   "metadata": {},
   "source": [
    "As we're using TensorFlow we can make use of the tf.data.Dataset object. First, we'll load in our Numpy binaries from file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d1ae6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "with open('movie-xids.npy', 'rb') as f:\n",
    "    Xids = np.load(f, allow_pickle=True)\n",
    "with open('movie-xmask.npy', 'rb') as f:\n",
    "    Xmask = np.load(f, allow_pickle=True)\n",
    "with open('movie-labels.npy', 'rb') as f:\n",
    "    labels = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08d93664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af67f928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 512)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9f6a2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fa7f66",
   "metadata": {},
   "source": [
    "We can take these three arrays and create a TF dataset object with them using from_tensor_slices like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d8a85a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-03 14:49:05.738088: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-01-03 14:49:05.738133: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((Xids, Xmask, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5d9f597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=(TensorSpec(shape=(512,), dtype=tf.int64, name=None), TensorSpec(shape=(512,), dtype=tf.int64, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf070af0",
   "metadata": {},
   "source": [
    "Each sample in our dataset is a tuple containing a single Xids, Xmask, and labels tensor. However, when feeding data into our model we need a two-item tuple in the format (, ). Now, we have two tensors for our inputs - so, what we do is enter our tensor as a dictionary:\n",
    "\n",
    "    {\n",
    "    'input_ids': ,\n",
    "    \n",
    "    'attention_mask': \n",
    "    }\n",
    "To rearrange the dataset format we can map a function that modifies the format like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efdd3058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_func(input_ids, masks, labels):\n",
    "    #convert three item tuple into two item tupke where the input item is a dictionary\n",
    "    return {'input_ids':input_ids, 'attention_mask':masks}, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99126df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map method to apply the transformation\n",
    "\n",
    "dataset = dataset.map(map_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81ef209b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec=({'input_ids': TensorSpec(shape=(512,), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(512,), dtype=tf.int64, name=None)}, TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25f3d3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the batch sizes of 16 and drop any samples that don't fit into chunks of 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f6d3761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)}, TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder=True)\n",
    "\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44fcf9a",
   "metadata": {},
   "source": [
    "Now our dataset samples are organized into batches of 16. The final step is to split our data into training and validation sets. For this we use the take and skip methods, creating and 90-10 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6e8e8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8778"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = 0.9\n",
    "\n",
    "# we need to calculate how many batches must be taken to create 90% training set\n",
    "size = int((Xids.shape[0] / batch_size) * split)\n",
    "\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87994887",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset.take(size)\n",
    "val_ds = dataset.skip(size) # skip method will skip 8.7k\n",
    "\n",
    "# free up memory\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8177f49a",
   "metadata": {},
   "source": [
    "Our two datasets are fully prepared for our model inputs. Now, we can save both to file using tf.data.experimental.save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de32416d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/2z/1gmxsnx16d34kv3j2t6lvbqw0000gn/T/ipykernel_25468/4166480079.py:1: save (from tensorflow.python.data.experimental.ops.io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.save(...)` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-03 14:49:12.475130: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "tf.data.experimental.save(train_ds, 'train')\n",
    "tf.data.experimental.save(val_ds, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64d63414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None),\n",
       "  'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)},\n",
       " TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f43b9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds.element_spec == train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d161b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.load('train', element_spec=train_ds.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e0b497b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_LoadDataset element_spec=({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)}, TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8edbd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
